{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LSoto\\AppData\\Local\\anaconda3\\envs\\keyEmotions\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "import mido\n",
    "\n",
    "from random import shuffle\n",
    "from miditok.utils import split_files_for_training\n",
    "from miditok.data_augmentation import augment_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi(midi_path):\n",
    "    \"\"\"\n",
    "    Load a midi file\n",
    "    \n",
    "    Input:\n",
    "        midi_path: str, path to the midi file\n",
    "    \n",
    "    Returns:\n",
    "        midi_data: mido.MidiFile, midi data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        midi_data = mido.MidiFile(midi_path)    \n",
    "        return midi_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {midi_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_remi(mid):\n",
    "    remi_tokens = []\n",
    "    current_time = 0\n",
    "    ticks_per_beat = mid.ticks_per_beat\n",
    "    tempo = 500000  \n",
    "\n",
    "    ticks_per_position = ticks_per_beat // 16\n",
    "\n",
    "    for track in mid.tracks:\n",
    "        remi_tokens.append(f\"Track {track.name}\")\n",
    "        for msg in track:\n",
    "            if not msg.is_meta:\n",
    "                current_time += msg.time\n",
    "\n",
    "                if msg.type == 'note_on' and msg.velocity > 0:\n",
    "                    position = (current_time % ticks_per_beat) // ticks_per_position\n",
    "                    remi_tokens.append(f\"Note-On: {msg.note}\")\n",
    "                    remi_tokens.append(f\"Velocity: {msg.velocity}\")\n",
    "                    remi_tokens.append(f\"Position: {position}\")\n",
    "                elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "                    remi_tokens.append(f\"Note-Off: {msg.note}\")\n",
    "                \n",
    "            elif msg.type == 'set_tempo':\n",
    "                tempo_bpm = mido.tempo2bpm(msg.tempo)\n",
    "                remi_tokens.append(f\"Tempo: {tempo_bpm}\")\n",
    "\n",
    "            if current_time % ticks_per_beat == 0:\n",
    "                remi_tokens.append(\"Bar\")\n",
    "\n",
    "    return remi_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(remi_tokens):\n",
    "    vocab = {token: idx for idx, token in enumerate(sorted(set(remi_tokens)))}\n",
    "    return vocab\n",
    "\n",
    "def tokenize_sequence(remi_tokens, vocab):\n",
    "    return [vocab[token] for token in remi_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_file = os.path.join(BASE_DIR, 'data', 'raw', \"Donkey Kong_SNES_Donkey Kong Country 2 Diddy's Kong Quest_Hot Head Bop.mid\")\n",
    "mid = load_midi(mid_file)\n",
    "\n",
    "remi_tokens = midi_to_remi(mid)\n",
    "vocab = build_vocab(remi_tokens)\n",
    "tokenized_sequence = tokenize_sequence(remi_tokens, vocab)\n",
    "print(tokenized_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": {(0, 4): 8, (4, 12): 4},\n",
    "    \"num_velocities\": 32,\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
    "    \"use_chords\": True,\n",
    "    \"use_rests\": False,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": False,\n",
    "    \"use_programs\": False,\n",
    "    \"num_tempos\": 32,  # number of tempo bins\n",
    "    \"tempo_range\": (40, 250),  # (min, max)\n",
    "}\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "\n",
    "tokenizer = REMI(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mid_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[43mmid_file\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mid_file' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(mid_file)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emotion_metadata(midi_file, emotion_level):\n",
    "    \"\"\"\n",
    "    Agrega un metadato de emoción como un evento MIDI personalizado.\n",
    "    \n",
    "    :param midi_file: Ruta al archivo MIDI.\n",
    "    :param emotion_level: Nivel de emoción (1-4).\n",
    "    :return: Objeto MIDI modificado.\n",
    "    \"\"\"\n",
    "    mid = mido.MidiFile(midi_file)\n",
    "\n",
    "    # Crear un evento de texto para representar el sentimiento\n",
    "    emotion_event = mido.MetaMessage(\n",
    "        type='text', text=f'Emotion:{emotion_level}', time=0\n",
    "    )\n",
    "    mid.tracks[0].append(emotion_event)\n",
    "    \n",
    "    return mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a dataset before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1424 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from miditok import REMI\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "midi_paths = list(Path(\"..\", \"data\", \"processed\", \"cleaned\").glob(\"**/*.mid\"))\n",
    "print(len(midi_paths), type(midi_paths))\n",
    "\n",
    "# Builds the vocabulary with BPE\n",
    "tokenizer.train(vocab_size=30000, files_paths=midi_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('C:/Users/luiss/Documents/VIU/TFM/KeyEmotions')\n",
    "\n",
    "raw_data_dir = Path(os.path.join(BASE_DIR, 'data', 'raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/prepared/train\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../src/config/default.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "train_dir = config['data']['prepared']['train']\n",
    "print(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All the music files provided are empty and contain no note.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m subset_chunks_dir \u001b[38;5;241m=\u001b[39m Path(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR, train_dir))\n\u001b[0;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(subset_chunks_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43msplit_files_for_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmidi_paths_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_chunks_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_overlap_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# for files_paths, subset in (\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#     (midi_paths_train, \"train\"),\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#     (midi_paths_valid, \"valid\"),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#         num_overlap_bars=2\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LSoto\\AppData\\Local\\anaconda3\\envs\\keyEmotions\\Lib\\site-packages\\miditok\\utils\\split.py:97\u001b[0m, in \u001b[0;36msplit_files_for_training\u001b[1;34m(files_paths, tokenizer, save_dir, max_seq_len, average_num_tokens_per_note, num_overlap_bars, min_seq_len)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     92\u001b[0m         path\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m save_dir\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**/*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_MUSIC_FILE_EXTENSIONS\n\u001b[0;32m     95\u001b[0m     ]\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m average_num_tokens_per_note:\n\u001b[1;32m---> 97\u001b[0m     average_num_tokens_per_note \u001b[38;5;241m=\u001b[39m \u001b[43mget_average_num_tokens_per_note\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mMAX_NUM_FILES_NUM_TOKENS_PER_NOTE\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Determine the deepest common subdirectory to replicate file tree\u001b[39;00m\n\u001b[0;32m    102\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m get_deepest_common_subdir(files_paths)\n",
      "File \u001b[1;32mc:\\Users\\LSoto\\AppData\\Local\\anaconda3\\envs\\keyEmotions\\Lib\\site-packages\\miditok\\utils\\split.py:318\u001b[0m, in \u001b[0;36mget_average_num_tokens_per_note\u001b[1;34m(tokenizer, files_paths)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(num_tokens_per_note) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    317\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll the music files provided are empty and contain no note.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(num_tokens_per_note) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(num_tokens_per_note)\n",
      "\u001b[1;31mValueError\u001b[0m: All the music files provided are empty and contain no note."
     ]
    }
   ],
   "source": [
    "# midi_paths = list(raw_data_dir.glob(\"**/*.mid\"))\n",
    "total_num_files = len(midi_paths)\n",
    "num_files_valid = round(total_num_files * 0.15)\n",
    "num_files_test = round(total_num_files * 0.15)\n",
    "shuffle(midi_paths)\n",
    "midi_paths_valid = midi_paths[:num_files_valid]\n",
    "midi_paths_test = midi_paths[num_files_valid:num_files_valid + num_files_test]\n",
    "midi_paths_train = midi_paths[num_files_valid + num_files_test:]\n",
    "\n",
    "print(len(midi_paths_train))\n",
    "\n",
    "subset_chunks_dir = Path(os.path.join(BASE_DIR, train_dir))\n",
    "os.makedirs(subset_chunks_dir, exist_ok=True)\n",
    "split_files_for_training(\n",
    "    files_paths=midi_paths_train,\n",
    "    tokenizer=tokenizer,\n",
    "    save_dir=subset_chunks_dir,\n",
    "    max_seq_len=1024,\n",
    "    num_overlap_bars=2\n",
    ")\n",
    "# for files_paths, subset in (\n",
    "#     (midi_paths_train, \"train\"),\n",
    "#     (midi_paths_valid, \"valid\"),\n",
    "#     (midi_paths_test, \"test\"),\n",
    "# ):\n",
    "#     subset_chunks_dir = Path(os.path.join(BASE_DIR, 'data', 'splits', f'dataset_{subset}'))\n",
    "#     os.makedirs(subset_chunks_dir, exist_ok=True)\n",
    "#     split_files_for_training(\n",
    "#         files_paths=files_paths,\n",
    "#         tokenizer=tokenizer,\n",
    "#         save_dir=subset_chunks_dir,\n",
    "#         max_seq_len=1024,\n",
    "#         num_overlap_bars=2\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates a Dataset and collator for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "midi_paths = list(Path(os.path.join(BASE_DIR, 'data', 'raw')).glob(\"**/*.mid\"))\n",
    "dataset = DatasetMIDI(\n",
    "    files_paths=midi_paths,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer[\"BOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id)\n",
    "data_loader = DataLoader(dataset=dataset, collate_fn=collator)\n",
    "\n",
    "# Using the data loader in the training loop\n",
    "for batch in data_loader:\n",
    "    print(\"Train your model on this batch...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from miditok.data_augmentation import augment_midi_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# Creates the tokenizer and list the file paths\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "data_path = Path(os.path.join(BASE_DIR, 'data', 'raw'))\n",
    "\n",
    "# A validation method to discard MIDIs we do not want\n",
    "# It can also be used for custom pre-processing, for instance if you want to merge\n",
    "# some tracks before tokenizing a MIDI file\n",
    "def midi_valid(midi) -> bool:\n",
    "    if any(ts.numerator != 4 for ts in midi.time_signature_changes):\n",
    "        return False  # time signature different from 4/*, 4 beats per bar\n",
    "    return True\n",
    "\n",
    "# Performs data augmentation on one pitch octave (up and down), velocities and\n",
    "# durations\n",
    "# midi_aug_path = Path(\"to\", \"new\", \"location\", \"augmented\")\n",
    "# augment_midi_dataset(\n",
    "#     data_path,\n",
    "#     pitch_offsets=[-12, 12],\n",
    "#     velocity_offsets=[-4, 5],\n",
    "#     duration_offsets=[-0.5, 1],\n",
    "#     out_path=midi_aug_path,\n",
    "# )\n",
    "tokenizer.tokenize_dataset(        # 2 velocity and 1 duration values\n",
    "    data_path,\n",
    "    Path(BASE_DIR, 'data'),\n",
    "    midi_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emotion_metadata(file_path, emotion_level, Returns_path):\n",
    "    \"\"\"\n",
    "    Agrega un metadato de sentimiento (1-4) a un archivo MIDI.\n",
    "\n",
    "    :param file_path: Ruta al archivo MIDI original.\n",
    "    :param emotion_level: Nivel de emoción (1-4).\n",
    "    :param Returns_path: Ruta para guardar el archivo MIDI modificado.\n",
    "    \"\"\"\n",
    "    midi = mido.MidiFile(file_path)\n",
    "\n",
    "    # Crear un evento MetaMessage con el sentimiento\n",
    "    emotion_event = mido.MetaMessage('text', text=f'Emotion:{emotion_level}', time=0)\n",
    "    \n",
    "    # Agregar el evento a la primera pista\n",
    "    midi.tracks[0].insert(0, emotion_event)\n",
    "    \n",
    "    # Guardar el archivo MIDI modificado\n",
    "    midi.save(Returns_path)\n",
    "    print(f\"Archivo MIDI guardado con metadato de sentimiento en: {Returns_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remi_to_midi(remi_tokens, Returns_file):\n",
    "#     midi = mido.MidiFile()\n",
    "#     track = mido.MidiTrack()\n",
    "#     midi.tracks.append(track)\n",
    "    \n",
    "#     current_time = 0\n",
    "#     ticks_per_beat = midi.ticks_per_beat  # Asume la resolución original\n",
    "    \n",
    "#     # Procesar tokens\n",
    "#     for token in remi_tokens:\n",
    "#         if token.startswith(\"Note-On\"):\n",
    "#             note = int(token.split(\":\")[1])\n",
    "#             track.append(mido.Message('note_on', note=note, velocity=64, time=current_time))\n",
    "#             current_time = 0  # Reinicia el tiempo acumulativo\n",
    "#         elif token.startswith(\"Note-Off\"):\n",
    "#             note = int(token.split(\":\")[1])\n",
    "#             track.append(mido.Message('note_off', note=note, velocity=0, time=current_time))\n",
    "#             current_time = 0\n",
    "#         elif token.startswith(\"Tempo\"):\n",
    "#             bpm = int(token.split(\":\")[1])\n",
    "#             tempo = int(60000000 / bpm)\n",
    "#             track.append(mido.MetaMessage('set_tempo', tempo=tempo, time=current_time))\n",
    "#             current_time = 0\n",
    "#         elif token.startswith(\"Bar\"):\n",
    "#             current_time += ticks_per_beat  # Avanzar al siguiente compás\n",
    "#         elif token.startswith(\"Position\"):\n",
    "#             position = int(token.split(\":\")[1])\n",
    "#             current_time += position * (ticks_per_beat // 16)  # Ajustar tiempo a la posición\n",
    "    \n",
    "#     midi.save(Returns_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keyEmotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
