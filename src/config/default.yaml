data:
    data_dir:              ./data
    raw:
        midi:              ./data/raw/midi
        metadata:          ./data/raw/metadata
    processed_dir:         ./data/processed
    processed:
        analysis:          ./data/processed/analysis
        cleaned:          ./data/processed/cleaned
    prepared_dir:          ./data/prepared

    # vocab_size:           30000   
    max_bars:             8
    grids_per_bar:        32

    train_ratio:          0.9
    val_ratio:            0.1

    # max_seq_len:          1024                 
    # enc_seqlen:       128
    # dec_seqlen:       1280               
    # batch_size:       4

model:
    n_head:              8
    vocab_size:          30000
    d_model:             128
    num_layers:          12
    lattent_dim:         64 # Latent space dimensionality
    emotion_dim:         4 # Dimensionality of emotion vector
    max_seq_len:         1024 # Maximum sequence length


    enc_n_layer:      12
    enc_n_head:       8
    enc_d_model:      512
    enc_d_ff:         2048
    dec_n_layer:      12
    dec_n_head:       8
    dec_d_model:      512
    dec_d_ff:         2048
    d_embed:          512
    d_latent:         128
    d_polyph_emb:     64
    d_rfreq_emb:      64
    cond_mode:        in-attn
    pretrained_params_path:      null
    pretrained_optim_path:       null

training:
    

    device:           cuda:0
    ckpt_dir:         ./ckpt/enc_dec_12L-16_bars-seqlen_1280
    trained_steps:    0
    max_epochs:       1000
    max_lr:           1.0e-4
    min_lr:           5.0e-6
    lr_warmup_steps:  200
    lr_decay_steps:   150000
    no_kl_steps:      10000
    kl_cycle_steps:   5000
    kl_max_beta:      1.0
    free_bit_lambda:  0.25
    constant_kl:      False
    ckpt_interval:    50
    log_interval:     10
    val_interval:     50

generate:
    temperature:                1.2
    nucleus_p:                  0.9
    use_latent_sampling:        False
    latent_sampling_var:        0.0
    max_bars:                   16       # could be set to match the longest input piece during generation (inference)
    dec_seqlen:                 1280     # could be set to match the longest input piece during generation (inference)
    max_input_dec_seqlen:       1024     # should be set to equal to or less than `dec_seqlen` used during training